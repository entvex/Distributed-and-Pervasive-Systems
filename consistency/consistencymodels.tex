\newpage
\section{Consistency models}

Consistency models\footnote{\cite{Takada2017}}\footnote{\cite{Abadi2012}} are used in distributed systems like shared memory storage, filesystems and databases to amend the issues that distributed write and read access could have to such a system. A consistency model define a given set of rules a operation must follow when accessing the data and can be seen as a contract between a running process (the programmer) and the system. If the process comply with this contract, then memory will be consistent and the output of reading, writing, or updating the memory will be predictable. For example in relational database systems, transactions abide by the ACID principle, where consistency ensures that any transition will bring the database from one valid state to the next and that data should follow a set of rules. Assume a relational database in a cluster that contain row $R_x$ and that this row is replicated to nodes $Node_a$ and $Node_b$. A client $C_i$ then writes $R_x$ on $Node_a$. Subsequently another client $C_j$ reads $R_i$ from $Node_b$. A consistency model has to determine if $C_j$ sees the write from $C_i$ or not.

\noindent Consistency models can be classified as strong or weak. A strong consistency model guarantees that the order and visibility of updates are equivalent to that of a centralized (non-replicated) system with only one process, that is updates are immediately replicated to all nodes. A weak consistency model does not make this guarantee. We will now look at both strong and weak models and consider them for a distributed system:

\noindent \textbf{Linearizability}: A strong consistency model that ensures that all operations appear to have run atomically (in isolation, independent from concurrent processes) in an order that is consistent with the global real-time ordering of operations. If a distributed database follows this model, than it would appear centralized to its clients. No matter how clients execute operations, the result would be the same as if they we executed in some sequential order and these operations appear in their order of executing.

\noindent \textbf{Sequential consistency}: A strong consistency model that mimics the linearizability one, but does not require that two independent operations from different clients respect the real-time ordering of operations in a system. With this model, operations can be re-ordered as long as each node observe the ordering consistently. A benefit of the two strong consistency models is that a client or programmer can replace a centralized system with a distributed one without facing data consistency issues.

\noindent \textbf{Client-centric consistency:} A range of various weak consistency models that makes guarantee to clients (users) of data. It ensures that a client may never see old versions of data, if they have already seen a newer one. This can be implemented with client-side caching, so if the client suddenly connects to a node with old data on it, then the application will present a cached version to the client. Still this may not be the newest version of the data globally, hence the weak consistency predicate.

\noindent \textbf{Eventual consistency}: A weak consistency model that guarantees that if an update has changed the state of one node in a system, after a undefined amount of time all nodes will reflect the same state, if no more values are changed. During this period of time (the inconsistency window) some nodes may be consistent and some may not. The size of this window is determined based on communication delay between nodes, system load and the number of nodes involved in the replication scheme. DNS (Domain Name System) and popular NoSQL datastores like Cassandra and DynamoDB implement a eventual consistency model. Eventual consistency is often refereed to as a liveness property, whereas a stronger model like linearizability is a safety property.

\noindent \textbf{Casual consistency}: A weak consistency model that captures the causal relationships between operations in the system, meaning that an update on a process becomes visible to another process only it has relationship with that process. If the operation on a process $P_i$ influences another write operation on process $P_j$, then these two operations are causally related. After updating $P_i$, it communicates to $P_j$ that a value was updated, and subsequent access by $P_j$ will return the updated value and writes will supersede it.

\noindent To recap, which model you choose is a tradeoff between availability and consistency. A system with high avaliabily may suffer from weak consistency and wise versa. We saw this in the PACELC theorem.